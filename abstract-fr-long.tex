
\chapter{Résumé étendu en français}


\section{Introduction}

Cloud computing (ou l'informatique en nuage) a révolutionné le monde industriel et académique de la technologie de l'information avec sa capacité à fournir de grandes quantités de ressources informatiques à la demande. La plupart des applications et des services que nous utilisons quotidiennement, qui comptent de plus en plus d'utilisateurs, tels que les réseaux sociaux, le courrier électronique, les jeux vidéo, la banque en ligne, les applications de santé et la diffusion vidéo, sont pris en charge par des plates-formes de cloud computing.


Malgré tous ses avantages, les centres de données en nuage (DC), les installations qui hébergent toute l'infrastructure nécessaire au cloud, ont une demande énergétique significative. L'Agence internationale de l'énergie (AIE) estime que les centres de données qui hébergent les plateformes de cloud computing ont consommé entre 240 et 320 TWh, soit environ 1\% de l'électricité finale mondiale générée en 2022~\cite{IEA_2022}. Pour mettre cette consommation d'énergie en perspective, cela suffit à fournir la demande énergétique annuelle de pays entiers. En 2022, sept pays avaient une consommation énergétique similaire à la demande énergétique des DC : la Grèce (316 TWh), Israël (304 TWh), la Biélorussie (297 TWh), la Suisse (292 TWh), la Hongrie (266 TWh), le Portugal (258 TWh) et le Maroc (257 TWh)~\cite{owidenergy}.

Les efforts à la fois de la communauté académique et de l'industrie tentent de réduire cette gigantesque consommation d'énergie. Une analyse de l'utilisation mondiale de l'énergie par les centres de données réalisée par \citet{masanet2020recalibrating} a montré que pendant la période entre 2010 et 2018, le trafic Internet des DC a augmenté de plus de 10 fois, on estime que la capacité de stockage des DC a augmenté de 25 fois, et la charge de travail et le nombre d'instances de calcul des DC ont augmenté de 6 fois. D'autre part, la consommation d'énergie n'a augmenté que de 6\% grâce aux améliorations suivantes : i) la virtualisation, qui a permis une augmentation de 5 fois du nombre moyen d'instances de calcul par serveur physique ; ii) des serveurs plus économes en énergie (une diminution d'un facteur de 4 en ce qui concerne la puissance utilisée pour le calcul et un facteur de 9 en termes de watts par téraoctet) ; et iii) des infrastructures économes en énergie, en particulier pour les besoins de refroidissement et d'alimentation électrique.



Il est incertain si les améliorations de l'efficacité dans le cloud computing permettront de compenser l'augmentation de la consommation électrique causée par la demande croissante en ressources informatiques à long terme. Dans le travail de \citet{koot2021usage}, les auteurs ont développé un modèle de prévision de la consommation d'énergie des centres de données en utilisant l'approche des modèles dynamiques de système. En considérant la période de 2016 à 2030, et le scénario avec la fin de la loi de Moore, qui prédit que le nombre de composants dans les circuits intégrés double chaque année~\cite{Mack_2011_moorelaw}, et la montée des applications industrielles de l'Internet des objets, la demande énergétique des centres de données pourrait atteindre 2,3\% de la génération mondiale d'électricité, elle doublera par rapport à ce qui a été rapporté par l'AIE pour l'année 2022~\cite{IEA_2022}.


La consommation d'électricité des centres de données a un impact environnemental en termes d'émissions de gaz à effet de serre (GES). Selon l'Agence internationale de l'énergie, 1\% des émissions de GES liées à l'énergie proviennent des centres de données et des réseaux de transmission de données~\cite{IEA_2022}. L'ampleur de cet impact dépend du type de source utilisé pour produire l'électricité. Le tableau~\ref{tab:co2_power_sources} présente les émissions pour les différents types de sources d'énergie pour produire 1 kWh d'énergie. Les émissions sont mesurées en utilisant le métrique de l'équivalent en dioxyde de carbone (ou \ch{CO2}-eq). Cette métrique est utilisée pour comparer différents GES en termes de leur potentiel de réchauffement global (PRG) en utilisant le dioxyde de carbone comme base : le méthane (\ch{CH4}) a un PRG de 25, ce qui signifie que l'émission de 1 g de \ch{CH4} dans l'atmosphère a le même impact environnemental que l'émission de 25 g de \ch{CO2}\cite{eurostat_co2_eq}. On peut observer que la production d'électricité à partir du charbon émet 77 fois plus de \ch{CO2} que l'éolien ou le nucléaire. En 2019, environ 70\% du trafic de données d'Internet était traité par les centres de données dans l'« Allée des centres de données », une région située en Virginie (États-Unis d'Amérique), qui était alimentée par moins de 2\% d'énergie renouvelable (énergie verte)\cite{clicking_clean_virginia}.


Afin de réduire leur impact environnemental, les principaux fournisseurs de cloud, tels qu'Amazon AWS, Apple, Google, Meta (anciennement Facebook) et Microsoft, se sont engagés à intégrer dans leurs opérations des centres de données une électricité à faible intensité carbonée produite par des sources renouvelables, et certains ont déjà déployé leurs projets pour atteindre l'objectif de minimiser l'empreinte carbone. En effet, Google a rapporté qu'en 2022, 64\% de l'électricité utilisée pour alimenter ses centres de données sur une base horaire provenait de sources renouvelables~\cite{google_sustainability_report_2023}, certains centres de données atteignant même jusqu'à 97\% d'utilisation d'énergie verte.
\begin{table}[!ht]

\caption{ Émissions (en g\,\ch{CO2}-eq) de différentes sources d'énergie par kWh d'électricité produite~\cite{nrel_lifecycle_2021}.}\label{tab:co2_power_sources} \centering

\begin{tabular}{|l|r|}
  \hline
  \textbf{Technologie de génération} & \textbf{Émissions ($\mathbf{g\,\ch{CO2}\text{-}eq/kWh}$)}   \\
  \hline  
  Charbon   & 1 010\\  
  \hline
  Pétrole   & 840\\
  \hline
  Gaz naturel   & 486\\
   \hline
  Biomasse   & 52 \\
  \hline
  Photovoltaïque   & 43 \\
  \hline
  Hydraulique & 21 \\
  \hline
  Nucléaire   & 13 \\
  \hline
  Éolien   & 13 \\
  \hline
\end{tabular}
\end{table}


Les plateformes cloud intègrent l'énergie renouvelable dans leurs opérations de différentes manières. Une possibilité est d'acheter de l'énergie verte auprès du réseau électrique local, bien que cela les rende dépendantes du mix énergétique du réseau, et toutes les régions du monde ne sont pas alimentées par des sources à faible émission de carbone. Une autre possibilité est de fabriquer leur propre infrastructure renouvelable sur site. Un aspect critique de la production d'électricité à partir d'énergies renouvelables qui doit être pris en compte pour ces deux possibilités est leur caractère intermittent : leur production fluctue dans le temps et est influencée par des variables telles que l'heure de la journée, le climat, la saison et la localisation géographique. Par exemple, les panneaux photovoltaïques ne produisent de l'énergie que lorsque le soleil brille, et pendant l'hiver, l'irradiation solaire est plus faible que durant l'été. Pour l'hydroélectricité, de longues périodes sans pluie affecteront la production d'énergie.



L'adoption de dispositifs de stockage d'énergie (DSE) dans les centres de données pour stocker l'énergie renouvelable~\cite{wang2012_EDCS} est une approche pour faire face à l'intermittence. Ces dispositifs sont déjà utilisés dans les centres de données comme sauvegarde temporaire en cas de pannes de courant. L'énergie verte provenant des DSE pourrait être utilisée lorsqu'il n'y a pas de production d'énergie verte ou lorsque la demande est supérieure à la production. Néanmoins, cette approche présente également certains défis pour décider quand utiliser ou recharger, étant donné les caractéristiques des DSE, telles que le taux d'autodécharge (ils perdent de l'énergie stockée avec le temps lorsqu'ils ne sont pas utilisés), le vieillissement (leur capacité maximale diminue avec le temps) et les taux de charge et de décharge limités (la puissance maximale pouvant être extraite ou rechargée).



Dans cette thèse, nous étudions comment réduire l'impact environnemental des centres de données de cloud computing, notamment en termes d'émissions de \ch{CO2}. L'utilisation de stratégies sensibles au carbone - des approches conscientes de leur empreinte carbone et utilisant ces informations pour prendre des décisions~\cite{schooler2021carbonaware} - est explorée pour réduire les émissions de \ch{CO2} à la fois dans l'exploitation et dans le dimensionnement des centres de données - en déterminant l'infrastructure renouvelable nécessaire sur site (surface des panneaux solaires, nombre d'éoliennes, capacité des DSE). En ce qui concerne les opérations des centres de données, nous exploitons la planification de la charge de travail en utilisant des approches follow-the-renewables - des stratégies qui migrent et allouent la charge de travail aux emplacements avec une disponibilité d'énergie renouvelable plus élevée~\cite{shuja2016sustainable} - et étudions leur impact à la fois sur la consommation d'énergie et la congestion du réseau. En ce qui concerne le dimensionnement, nous modélisons notre problème en utilisant une formulation de programme linéaire (PL) qui prend en compte les caractéristiques de chaque emplacement de centre de données en termes de besoins de refroidissement et de mix énergétique local du réseau, ainsi que le fait que l'infrastructure renouvelable génère un impact environnemental. Plus de détails sur la structure et les contributions de cette thèse sont présentés dans la section suivante.


Cette thèse est structurée en six chapitres, comprenant ce chapitre introductif. Une vue d'ensemble du contenu de chaque chapitre et de leurs contributions respectives est décrite ci-après.

Dans le Chapitre~\ref{chap:background}, le lecteur est introduit aux concepts nécessaires pour comprendre la recherche réalisée dans cette thèse. En particulier, le chapitre contient une description du scénario général du cloud computing, comment on peut mesurer l'impact environnemental des plateformes cloud, un aperçu des algorithmes d'ordonnancement dans le contexte du cloud computing, et la définition des stratégies sensibles au carbone - particulièrement, les approches explorées dans cette thèse : follow-the-renewables et le dimensionnement. Enfin, les travaux connexes utilisés comme inspiration ou comme bases pour nos solutions proposées sont également présentés dans ce chapitre.

Une analyse de l'adoption de la stratégie sensible au carbone follow-the-renewables et son impact sur la consommation d'énergie et la congestion du réseau est présentée dans le Chapitre~\ref{chap:smartgreens}. La solution proposée consiste en un algorithme qui prend en compte la topologie et l'utilisation du réseau pour planifier la migration de la charge de travail. À travers des expériences computationnelles avec des données du monde réel pour la charge de travail, l'infrastructure cloud, et un simulateur qui utilise des modèles réalistes validés par la communauté scientifique pour la consommation d'énergie et l'utilisation du réseau, les résultats montrent que la solution proposée surpasse les références en termes de consommation d'énergie, de consommation d'énergie non renouvelable et de congestion du réseau.


Le Chapitre~\ref{chap:ccgrid} introduit une stratégie sensible au carbone qui peut être combinée avec le suivi des renouvelables pour réduire l'empreinte carbone des plateformes de cloud computing en exploitation : le dimensionnement de l'infrastructure renouvelable. Cette stratégie consiste à déterminer la surface requise des panneaux solaires sur site et la capacité des batteries pour fournir la demande d'énergie des centres de données.


La solution proposée consiste en une formulation de Programme Linéaire qui aborde à la fois la planification de la charge de travail en utilisant le suivi des renouvelables et le dimensionnement de l'infrastructure renouvelable sur site. En modélisant ces deux sous-problèmes comme un seul problème, il est possible d'évaluer s'il est plus efficace d'exécuter la charge de travail dans d'autres emplacements géographiques ou d'augmenter la surface des panneaux solaires et la capacité des batteries pour atteindre l'objectif de réduction des émissions de \ch{CO2}. Le modèle n'utilise que des variables linéaires, ce qui lui permet d'être résolu de manière optimale en temps polynomial, ce qui est essentiel à l'échelle des plateformes de cloud computing qui comptent des millions de serveurs et exécutent des centaines de millions de tâches computationnelles chaque jour. D'autres aspects importants de la modélisation sont qu'elle prend en compte les caractéristiques de chaque emplacement géographique des centres de données en termes de besoins de refroidissement, le mix énergétique du réseau électrique local (qui peut avoir une part de sources d'énergie renouvelable), et le fait que la fabrication de panneaux solaires et de batteries a un impact environnemental.

Les résultats démontrent que la configuration hybride qui combine à la fois l'infrastructure renouvelable sur site et le réseau électrique régulier surpasse en termes d'émissions de \ch{CO2} les stratégies ayant un centre de données uniquement alimenté par l'énergie produite par son infrastructure renouvelable locale, avec une réduction d'environ 30\%, et n'utilisant que l'énergie du réseau électrique régulier, avec une réduction d'environ 85\%.

Le modèle introduit au Chapitre~\ref{chap:ccgrid} se concentre sur l'exploitation à court terme (une année). Dans le Chapitre~\ref{chap:ccgrid-extension}, nous étendons le modèle pour évaluer comment minimiser les émissions de carbone des opérations des centres de données cloud à long terme.

Les modifications et analyses suivantes ont été réalisées : l'impact environnemental de tout le cycle de vie de l'infrastructure renouvelable (de la fabrication, de l'exploitation et du recyclage) est pris en compte pour rendre le modèle plus proche du monde réel ; une analyse des avantages et des défis liés à l'inclusion de turbines éoliennes dans l'infrastructure renouvelable sur site ; une évaluation de la sensibilité du modèle aux entrées, en particulier les conditions climatiques et les données sur les émissions du réseau ; une analyse de la réduction possible des émissions de \ch{CO2} en adoptant la flexibilité de retarder une partie de la charge de travail, ce qui pourrait être utilisé pour atténuer les impacts du surdimensionnement de l'infrastructure renouvelable ; une discussion des coûts monétaires (en dollars) associés à l'infrastructure renouvelable sur site, ainsi que des compromis entre la minimisation de l'empreinte carbone et la réduction des coûts pour les centres de données ; et décider de fabriquer de nouveaux serveurs au fil des ans qui peuvent être plus économes en énergie, en considérant que leur fabrication émet également du carbone. Cette modélisation peut être utilisée pour guider les décideurs dans leurs efforts pour réduire l'empreinte carbone des centres de données cloud.

Enfin, le Chapitre~\ref{chap-conclusion} présente une discussion des principales contributions de cette thèse, ainsi que des trajectoires de recherche futures possibles.

Dans ce qui suit, nous présentons un résumé des principales contributions de chaque chapitre. Le lecteur peut consulter le manuscrit original (en anglais) pour avoir accès à plus de détails.

%% Background %%%%%%%%%%%%%%%%

\section{Contexte}

Cette section fournit les connaissances fondamentales nécessaires au lecteur pour comprendre les chapitres suivants de cette thèse. Tout d'abord, le scénario général de l'informatique en nuage est présenté dans la Section~\ref{sec:cloud_resume}. La Section~\ref{sec:measuring_environmental_impact_resume} présente comment on peut mesurer l'impact environnemental des plateformes de cloud computing. Ensuite, une introduction à l'ordonnancement dans le contexte des clouds est présentée dans la Section~\ref{sec:scheduling_cloud_resume}. Les approches existantes explorées dans cette thèse pour réduire l'impact environnemental des plateformes de cloud computing sont discutées dans la Section~\ref{sec:carbon_responsive_resume}, et les travaux utilisés dans cette thèse comme inspiration et références sont également présentés. Enfin, la Section~\ref{sec:summary_background_resume} résume cette section.
\subsection{Cloud computing}

\label{sec:cloud_resume}

Le cloud computing a été introduit par l'industrie pour résoudre les problèmes les plus importants du commerce électronique de l'époque. Avant l'avènement du cloud computing et de son accès à la demande aux ressources informatiques, les utilisateurs et les entreprises devaient acheter leur propre infrastructure informatique pour déployer leurs services ou applications. En cas de pic soudain de demandes, il était souvent difficile de mettre à l'échelle l'infrastructure informatique à temps pour gérer la demande de charge informatique. Malgré ses aspects révolutionnaires en technologie de l'information, le cloud computing n'est pas classé comme un nouveau paradigme dans la recherche en informatique. En fait, c'est l'évolution de la recherche dans différents domaines de l'informatique, tels que les clusters, les grilles, l'informatique autonome et l'informatique ubiquitaire.

L'un des éléments critiques qui permettent le cloud computing est la technologie de virtualisation, dans laquelle les ressources informatiques d'une machine physique sont converties en ressources virtuelles pouvant être partagées entre de nombreux utilisateurs et applications, également connue sous le nom de multi-tier. Les principales idées de la virtualisation proviennent de la fin des années 1950 et du début des années 1960 avec le paradigme de multiprogrammation, et aujourd'hui, la recherche sur les machines virtuelles (VM) et les containers continuent d'étudier les compromis décrits dans la littérature de la multiprogrammation en termes de portabilité, de performance et de sécurité~\cite{randall2020_virtualization}.

Les plateformes de cloud computing prennent généralement en charge des services à trois niveaux distincts : IaaS (Infrastructure en tant que Service), PaaS (Plateforme en tant que Service) et SaaS (Logiciel en tant que Service)~\citep{fos08}. Au premier niveau, Infrastructure en tant que Service (IaaS), la plateforme accorde aux utilisateurs l'accès aux ressources matérielles (telles que le traitement et le stockage) et leur facture leur utilisation. Des services tels qu'Amazon EC2 (Elastic Cloud Computing) Service et Amazon S3 (Simple Storage Service) sont des exemples de clouds IaaS. Au deuxième niveau, Plateforme en tant que Service (PaaS), le fournisseur prend en charge un environnement complet de développement, de test et de déploiement pour le développeur d'applications, ce qui signifie habituellement que le développeur devra suivre un modèle de développement spécifique et accepter des restrictions sur la manière de modéliser le logiciel en échange de la scalabilité fournie. Un exemple est le Google App Engine. Enfin, au troisième niveau, Logiciel en tant que Service (SaaS), des applications spécifiques sont proposées aux utilisateurs via Internet, et le tarif est proportionnel à l'utilisation de l'application. Nous pouvons citer les applications de bureautique Google Docs comme exemples.


Les plates-formes de cloud computing modernes sont composées de plusieurs centres de données répartis géographiquement dans le monde entier, également appelés fédérations de cloud ou multi-clouds. La figure~\ref{fig:dc_locations} illustre les emplacements des centres de données cloud de Microsoft Azure qui, au total, sont composés de millions de serveurs physiques~\cite{roach2021_microsoftazure}. Le besoin d'une infrastructure géographiquement distribuée provient de la nécessité de répondre à la demande du grand nombre d'utilisateurs et de réduire le temps de réponse pour leurs applications, ainsi que pour des raisons de sécurité et de redondance. Par exemple, si un centre de données dans une région tombe en panne en raison d'un problème d'alimentation ou d'une attaque de piratage, une autre région pourrait temporairement recevoir la charge de calcul. Enfin, cette infrastructure distribuée permet d'explorer différentes approches pour réduire l'impact environnemental de l'exploitation des centres de données, et plus de détails sur ces stratégies sont donnés dans la section~\ref{sec:carbon_responsive_resume}.


\subsection{Mesurer l'impact environnemental des platesformes de cloud computing}

\label{sec:measuring_environmental_impact_resume}


Le protocole GHG~\cite{ghgprotocol2004} a été développé comme moyen de standardiser la mesure et la déclaration de l'impact environnemental des entreprises. Il prend en compte six types de gaz à effet de serre (GES) du protocole de Kyoto : le dioxyde de carbone (\ch{CO2}), le méthane (\ch{CH4}), l'hexafluorure de soufre (\ch{SF6}), le protoxyde d'azote (\ch{N2O}), les hydrofluorocarbures (HFC) et les perfluorocarbures (PFC).


Le protocole comporte trois domaines pour quantifier les émissions directes et indirectes :

\begin{itemize}
\item \textbf{Scope 1 - Émissions directes de GES} : prend en compte les émissions générées par les sources que l'entreprise possède ou contrôle. Dans le contexte du cloud computing, cela pourrait provenir de l'électricité générée lors d'une surtension, et des générateurs devraient être utilisés comme solution de secours ; le transport des produits, des matériaux et des employés à l'aide des véhicules de l'entreprise ; et le refroidissement de l'infrastructure du centre de données~\cite{gupta2021_chasingcarbon}.
\item \textbf{Scope 2 - Émissions indirectes de GES liées à l'électricité} : prend en compte les émissions générées par l'électricité consommée.
\item \textbf{Scope 3 - Autres émissions indirectes de GES} : Ce domaine est facultatif et prend en compte les émissions issues de la production ou de l'extraction des matériaux et des combustibles achetés, par exemple, les équipements informatiques (tels que les serveurs et les routeurs) ainsi que la construction des installations du centre de données. Les émissions liées au transport sont également incluses dans ce domaine si elles proviennent de véhicules non possédés par l'entreprise.
\end{itemize}  

Les principaux acteurs du cloud fournissent déjà des rapports de durabilité et utilisent le Protocole GHG. Dans le rapport de durabilité de Meta pour 2023~\cite{meta_sustainability_report_2023}, il est estimé que 1\% des émissions proviennent du Scope 1, moins de 1\% du Scope 2 et 99\% du Scope 3. De plus, il est indiqué que les émissions opérationnelles ont été réduites de 94\% par rapport à 2017 grâce aux engagements en matière d'énergie renouvelable. Un autre exemple remarquable est le rapport environnemental de Google pour 2023~\cite{google_sustainability_report_2023}, où il est estimé que 1\% des émissions proviennent du Scope 1, 24\% du Scope 2 et 74\% du Scope 3. Google indique également que la majeure partie des émissions du Scope 3 proviennent de la fabrication du matériel et des biens d'équipement qu'ils ont achetés et de la construction des installations de centres de données.

Dans cette thèse, l'impact environnemental est uniquement évalué en termes d'empreinte carbone, en utilisant la métrique équivalente en \ch{CO2} (\ch{CO2}-eq). Cette décision a été prise en raison du manque de données pour mesurer d'autres impacts environnementaux, tels que l'utilisation de l'eau, et les impacts causés par l'extraction de minéraux bruts pour fabriquer les circuits intégrés.



\subsection{Ordonnancement pour les plateformes de cloud computing}
\label{sec:scheduling_cloud_resume}

Les problèmes d'ordonnancement sont des problèmes d'optimisation combinatoire où, étant donné la description des caractéristiques d'un ensemble de ressources informatiques ($\alpha$) et d'un ensemble de tâches ($\beta$), l'objectif est de trouver une allocation (dans le temps) des ressources aux tâches qui minimise certains critères d'optimisation ($\gamma$). Ces problèmes sont généralement désignés en utilisant la notation \mbox{$\alpha$ $\vert$ $\beta$ $\vert$ $\gamma$}, introduite par Graham~\citep{graham}.

Le critère le plus couramment étudié dans les problèmes de calcul haute performance est appelé makespan (également noté par $C_{\max}$), qui indique le moment où la dernière tâche composant une application termine son exécution. Lorsque les ressources informatiques disponibles sont identiques et connues à l'avance, et que nous cherchons à minimiser le makespan, typiquement le cas dans les problèmes d'ordonnancement dans les grappes et les grilles de calcul, le problème est fortement NP-difficile~\citep{Garey}. Ce problème est désigné par $P,\vert,\vert,C_{\max}$ dans la notation de Graham.

Pour le problème de recherche exploré dans cette thèse, $\alpha$ représente les ressources informatiques (mémoire et CPU) des serveurs des centres de données ainsi que leurs informations sur la disponibilité de sources d'alimentation à faible intensité carbonique, $\beta$ représente les exigences des machines virtuelles en termes de temps d'exécution, de délai, de mémoire et de CPU, et $\gamma$ représente la réduction de la consommation d'énergie carbonée.


Il est connu, d'après les travaux de~\citet{graham} et~\citet{Garey}, que la classe d'algorithmes gloutons connus sous le nom d'algorithmes de liste fournit des heuristiques rapides et efficaces pour l'ordonnancement des tâches sur des ordinateurs parallèles. Ces algorithmes ont une garantie d'approximation de $2 -1 /m$ dans le pire des cas, mais sont remarquablement efficaces en pratique, surtout lorsque le rapport entre le nombre de tâches et le nombre de ressources informatiques disponibles est élevé. Parmi les algorithmes de liste les plus couramment utilisés, on trouve le Longest Processing Time first (LPT) et le Shortest Processing Time first (SPT), pour les plateformes homogènes, et l'algorithme Heterogeneous Earliest Finish Time (HEFT), pour les plateformes hétérogènes.

La stratégie de consolidation des machines virtuelles illustre un exemple de problème d'ordonnancement dans le cloud computing rendu possible par la virtualisation. Elle consiste à utiliser des migrations en direct, migrer la VM entre différentes machines tout en étant en cours d'exécution, c'est-à-dire sans préemption, pour réallouer les VM afin d'atteindre le nombre minimum de machines physiques utilisées, et éteindre les machines devenues inactives pour économiser de l'énergie. Le lecteur peut consulter le travail de~\citet{10.1145/3470972} pour une revue systématique de la littérature sur de telles techniques.

Les algorithmes gloutons ont été adoptés dans certaines des solutions proposées dans cette thèse, ainsi que dans la plupart des travaux connexes utilisés comme bases et sources d'inspiration. La justification de cette décision est que, bien qu'ils ne fournissent pas la solution optimale, ils peuvent fournir une solution acceptable dans un laps de temps raisonnable, ce qui est important compte tenu de la taille de la charge de travail avec des millions de tâches et des restrictions telles que la date limite, le temps de réponse, et autres. La section suivante présente ces stratégies au lecteur.



\subsection{Carbon-Responsive Computing}

\label{sec:carbon_responsive_resume}

De nombreux efforts, tant de la part du milieu universitaire que de l'industrie, sont déployés pour réduire l'impact environnemental des technologies de l'information. Le terme \guillemotleft Carbon-Responsive Computing\guillemotright a été créé pour décrire les stratégies qui explorent le déplacement de la charge de travail informatique à la fois dans le temps et dans l'espace dans le but de réduire l'empreinte carbone de l'opération~\cite{schooler2021carbonaware}.

Il existe trois niveaux de Carbon-Responsive computing. Dans le premier, Carbon-aware computing, le système connaît l'intensité carbone de l'électricité utilisée par ses charges de travail ou son équipement informatique. Dans le second, carbon-responsive computing, les informations sur l'intensité carbone sont prises en compte pour prendre des décisions. La dernière étape, carbon-resilient computing, étudie comment gérer et intégrer des éléments réactifs au carbone et quelles modifications sont nécessaires dans l'informatique et l'infrastructure d'alimentation pour réduire l'empreinte carbone.


Dans cette thèse, une étude de la stratégie carbon-aware follow-the-renewables est présentée (Section~\ref{sec:followtherenewables_resume}), ainsi que la stratégie carbon-resilient de dimensionner l'infrastructure renouvelable (Section~\ref{sec:sizing_resume}).


\subsubsection{Follow-the-renewables}

\label{sec:followtherenewables_resume}

Comme nous l'avons vu dans la Section~\ref{sec:cloud_resume}, les plates-formes de cloud computing modernes sont réparties géographiquement à travers le monde, ayant des centres de données dans de nombreuses combinaisons de latitudes, de longitudes et de fuseaux horaires. Étant donné que chaque emplacement a un potentiel différent pour générer de l'énergie renouvelable, et que l'énergie renouvelable est intermittente - le soleil ne brille que pendant la journée, et le vent ne souffle pas tout le temps à des vitesses suffisantes pour faire tourner les pales des éoliennes - les algorithmes de planification peuvent utiliser cette caractéristique pour planifier l'exécution de la charge de travail dans les endroits où il y a plus de disponibilité d'énergie verte. Dans la littérature, le terme \guillemotleft follow-the-renewables\guillemotright~\cite{shuja2016sustainable} describes this strategy. Cette stratégie se concentre sur le Scope 2 du Protocole GHG, car elle planifie la charge de travail à l'emplacement qui utilise moins d'énergie intensive en carbone provenant de sources renouvelables.


%\guillemotleft and \guillemotright
\subsubsection{Dimensionner l'infrastructure renouvelable}


\label{sec:sizing_resume}


Il existe deux options principales pour répondre à la demande d'électricité à faible intensité en carbone de la fédération cloud. Le propriétaire du centre de données peut acheter de l'électricité verte auprès du réseau électrique local intégrant les énergies renouvelables, ce qui les rend dépendants du réseau, et toutes les localisations ne permettent pas cette possibilité, ou il peut installer une infrastructure renouvelable locale dans les centres de données. Pour cette dernière option, le principal problème est de décider des dimensions de l'infrastructure renouvelable nécessaire, par exemple, la surface requise des panneaux solaires, le nombre d'éoliennes et la capacité des batteries (pour stocker l'énergie verte et l'utiliser lorsque c'est opportun) pour alimenter le centre de données et minimiser son empreinte carbone. Ce problème est connu sous le nom de dimensionnement ou de planification de la capacité dans la littérature (sizing, dimensioning ou capacity planning en anglais). De nombreux facteurs doivent être pris en compte dans la décision de dimensionnement : les coûts de fabrication et d'exploitation de ces appareils, le potentiel de production d'énergie compte tenu des conditions climatiques et de la localisation géographique, et le fait que ces appareils présentent également un impact environnemental tout au long de leur cycle de vie ne peut être négligé.

La stratégie de dimensionnement de l'infrastructure renouvelable prend en compte les Scopes 1, 2 et 3 du Protocole GHG : les émissions de carbone directes de la production d'électricité dans le centre de données, les émissions liées à la consommation d'électricité du réseau électrique ordinaire, et les autres émissions de GES indirectes provenant de la fabrication et du cycle de vie de l'infrastructure renouvelable et de l'équipement informatique.

%%%% SMARTGREENS
\section{Follow-the-renewables et leur impact sur le réseau et la consommation énergétique}


L'approche \guillemotleft follow-the-renewables\guillemotright (le lecteur peut consulter le Chapitre~\ref{chap:background} pour plus de détails) est une stratégie intéressante pour atténuer l'intermittence de la disponibilité de l'énergie renouvelable sans avoir besoin d'utiliser des dispositifs de stockage d'énergie. Par exemple, lorsque c'est la nuit dans l'emplacement où se trouve un centre de données A, la charge de travail pourrait être migrée vers un autre centre de données B où le soleil brille encore pour utiliser l'énergie solaire, comme illustré dans la Figure~\ref{fig:ex_follow_the_renewables}.

Malgré ses avantages, on ne peut négliger les limitations de la stratégie follow-the-renewables. Tout d'abord, le processus de migration d'une machine virtuelle entre différents centres de données consomme lui-même de l'énergie : il utilise des dispositifs réseau (comme des commutateurs et des routeurs) et une tâche informatique pour le processus de migration en direct. L'algorithme de planification doit prendre en compte cette consommation d'énergie avant de décider si la migration est avantageuse. Deuxièmement, les liens de communication réseau qui connectent les serveurs à l'intérieur du centre de données et les différents centres de données peuvent souffrir de congestion, ce qui peut augmenter la durée de la migration. Cela entraîne une computation et une consommation d'énergie inutiles à la fois sur les serveurs d'origine et de destination : le serveur qui envoie la machine virtuelle doit attendre la fin du processus de migration pour libérer ses ressources et recevoir des machines virtuelles supplémentaires, ou il pourrait également être éteint pour économiser de l'énergie ; le serveur qui reçoit la machine virtuelle ne commencera à exécuter la nouvelle machine virtuelle qu'après la fin du processus de migration. Un algorithme de planification efficace doit prendre en compte ces facteurs pour réduire l'empreinte carbone des opérations des centres de données.

Le travail de Camus et al.~\citet{SAGITTA,NEMESIS} a étudié la planification de la charge de travail en nuage, sous forme de machines virtuelles (virtual machine ou VM en anglais), sur des centres de données géographiquement répartis afin de minimiser la consommation d'énergie non renouvelable. Il a proposé différents modèles stochastiques pour estimer la production d'énergie renouvelable et des algorithmes heuristiques gloutons pour allouer des tâches aux serveurs. Les VM peuvent être migrées pendant leur exécution vers un ordinateur situé dans le même centre de données (consolidation des serveurs intra-DC) ou vers un ordinateur dans un centre de données situé dans un autre emplacement géographique (\guillemotleft follow-the-renewables\guillemotright). L'algorithme de planification prend en compte le coût réseau de la migration.



Le Chapitre~\ref{chap:smartgreens} présente une extension de ce travail avec une analyse de l'impact indirect de l'utilisation de l'approche \guillemotleft follow-the-renewables\guillemotright sur la consommation d'énergie. Cet impact peut être divisé en deux catégories : direct et indirect. La consommation d'énergie des dispositifs réseau entraîne l'impact direct, et comme la consommation d'énergie ne varie pas significativement en fonction de l'utilisation du dispositif~\cite{energy_network_devices}, nous supposons que la consommation d'énergie des dispositifs réseau est statique. Pour l'impact indirect, il est généré par la migration en direct des VM, qui utilise le réseau pour transférer toutes les données liées à la tâche vers la machine de destination, ainsi que la tâche de calcul nécessaire pour effectuer cette migration en direct. Plus précisément, ce chapitre présente les contributions suivantes :

\begin{itemize}
    \item une analyse de l'impact de ne pas prendre en compte le réseau (bande passante, latence et topologie) à la fois dans la consommation d'énergie et la congestion du réseau ;
    \item un algorithme d'estimation précis pour le temps nécessaire à la migration d'une machine virtuelle qui prend en compte la topologie du réseau, la bande passante du lien et la latence ;
    \item un algorithme d'ordonnancement pour la migration en direct des VM qui utilise l'algorithme d'estimation et a la même consommation d'énergie brune ou inférieure aux références, sans congestion du réseau.
\end{itemize}
    
Le chapitre~\ref{chap:smartgreens} est organisé comme suit. Dans la Section~\ref{sec:nemesis}, le modèle de~\citet{NEMESIS}, fondement de ce travail, est résumé. La Section~\ref{sec:modeling_smargreens} détaille la nouvelle méthode de planification pour les migrations, tandis que la Section~\ref{sec:simulations_smargreens} est consacrée aux paramètres de simulation. Les résultats sont détaillés dans la Section~\ref{sec:results_smargreens}. Enfin, la Section~\ref{sec:conclusion_smargreens} résume le chapitre.

Dans ce qui suit, nous présentons la discussion générale du chapitre~\ref{chap:smartgreens}. Réduire l'impact environnemental de l'exploitation des plates-formes de cloud computing, en particulier l'empreinte carbone générée par leur consommation énergétique gigantesque, est un problème complexe et difficile actuellement abordé sous différents angles. Dans ce chapitre, nous nous concentrons sur la stratégiefollow-the-renewables et étudions l'impact indirect sur la consommation d'énergie causé par la charge supplémentaire générée dans le réseau. Les expériences étaient basées sur des données du monde réel pour l'infrastructure cloud, les charges de travail et la production d'énergie photovoltaïque.

Ce chapitre démontre que l'impact indirect sur le réseau de la consommation d'énergie dans les multi-clouds pour les approches \guillemotleft follow-the-renewables\guillemotright est généré par de mauvaises politiques de planification pour les migrations, ce qui entraîne une congestion du réseau. En effet, les migrations en direct rivalisent pour la bande passante disponible des liens du réseau, affectant non seulement les applications qui s'exécutent à l'intérieur des machines virtuelles, mais aussi la durée du processus de migration. Étant donné que la migration d'une machine virtuelle consomme également de l'énergie, proportionnellement à sa durée, et que la charge de travail sera envoyée aux centres de données en utilisant de l'énergie plus verte (\guillemotleft folllow-the-renewables\guillemotright), la consommation d'énergie supplémentaire est en réalité une énergie gaspillée qui pourrait être utilisée pour alimenter la plate-forme cloud. De plus, l'adoption de la stratégie \guillemotleft folllow-the-renewables\guillemotright doit prendre en compte l'ensemble de l'exécution de la charge de travail : les algorithmes de pointe qui n'utilisaient que les informations sur l'énergie verte pour la planification initiale et ne migraient pas la charge de travail lorsque la disponibilité de l'énergie renouvelable changeait avaient la plus forte consommation d'énergie non renouvelable.


L'algorithme d'estimation proposé pour la durée des migrations en direct, qui utilise en entrée des informations sur le réseau de communication des centres de données (latence des liens réseau, bande passante et topologie), est précis. En utilisant cet algorithme d'estimation et en utilisant les caractéristiques du réseau du cloud en entrée, la planification des migrations de c-NEMESIS a pu augmenter le nombre de migrations d'au moins trois fois sans congestion réseau, tout en maintenant ou en réduisant la consommation d'énergie non renouvelable par rapport à d'autres travaux de l'état de l'art.


\section{Dimensionnement de l'infrastructure renouvelable des centres de données cloud}

Dans le chapitre~\ref{chap:smartgreens}, nous avons vu l'adoption de la technique carbon-aware follow-the-renewables appliquée à un multi-cloud distribué sur un pays et ses inconvénients, tels que la congestion du réseau et la consommation d'énergie supplémentaire, si elle n'est pas utilisée correctement. Maintenant, le lecteur est introduit à une stratégie réactive au carbone qui peut être combinée avec \guillemotleft follow-the-renewables\guillemotright dans notre quête de réduction de l'empreinte carbone de l'exploitation des fédérations cloud : le dimensionnement de l'infrastructure renouvelable. Cette stratégie consiste à définir combien d'investissement doit être réalisé, par exemple, en définissant la superficie des panneaux solaires (lorsque l'on considère l'énergie solaire), le nombre d'éoliennes et la capacité des dispositifs de stockage d'énergie (comme les batteries lithium-ion) qui doivent être fabriqués.



Le scénario considéré dans le chapitre~\ref{chap:ccgrid} présente quelques différences pour mieux représenter les fournisseurs de cloud modernes. Tout d'abord, il est considéré que les centres de données (DC) sont répartis géographiquement dans le monde entier, représentant ainsi de véritables fournisseurs de cloud tels que Google et Microsoft (comme on peut le voir dans la Figure~\ref{fig:dc_locations}). De nombreuses raisons justifient la nécessité de centres de données géographiquement distribués : i) répondre à la demande croissante en nombre d'utilisateurs ; ii) redondance, par exemple, en cas de problème dans une région, la charge de travail peut être déplacée vers un autre emplacement ; iii) réduire la latence ou le temps de réponse pour les utilisateurs. Cette distribution géographique permet également une meilleure exploitation des sources renouvelables, car il existe des conditions climatiques variables, les niveaux d'irradiation solaire diffèrent entre les pays, tout comme la vitesse et la fréquence du vent. Deuxièmement, de nombreux endroits dans le monde ont la présence de sources à faible intensité de carbone dans leur réseau électrique local, donc en réalité, il n'y a pas seulement une classification en vert et marron (comme on l'a vu dans le chapitre précédent). La classification en vert et marron avait du sens dans le scénario précédent, car seul un pays était considéré, et l'énergie renouvelable était moins carbonée que le réseau électrique local. Enfin, des dispositifs de stockage d'énergie peuvent être utilisés pour stocker la surproduction d'énergie renouvelable et l'utiliser lorsque c'est opportun.


Un point qui ne peut être négligé est que la fabrication de l'infrastructure renouvelable présente également un impact environnemental : les batteries ont un niveau de charge idéal qui peut améliorer leur durée de vie, ce qui peut réduire la fréquence de remplacement, mais d'autre part, cela les rend surdimensionnées\cite{batteries_baumman}, et leurs taux de recyclage doivent encore s'améliorer\cite{bateries_RAHMAN}; et en considérant l'état actuel de l'art des panneaux solaires, s'ils produisent 40\% de l'électricité mondiale d'ici à 2050, ils consommeront environ 5\% du budget actuel de \ch{CO2}~\cite{solar_co2}.

Dans le chapitre~\ref{chap:ccgrid}, nous explorons l'adoption des deux stratégies, dimensionner les panneaux solaires et les batteries et planifier avec follow-the-renewables pour réduire l'empreinte carbone de l'exploitation des plates-formes cloud existantes. Plus précisément, le chapitre présente les contributions suivantes :

\begin{itemize}
    
    \item les deux sous-problèmes, le dimensionnement des panneaux solaires et des batteries, et la planification de la charge de travail, sont modélisés comme un seul problème, ce qui permet d'évaluer des scénarios tels que : faut-il augmenter la capacité de la batterie ou la surface des panneaux solaires, ou faut-il planifier la charge de travail dans un centre de données situé dans une autre partie du monde ?
    
    \item nous proposons un modèle qui utilise une approche de programmation linéaire (linear programming ou LP en anglais) avec des variables réelles, nous permettant de résoudre de manière optimale le problème que nous abordons en temps polynomial en utilisant des solveurs LP classiques. Cela permet d'évaluer un grand nombre de scénarios sur de larges horizons temporels (c'est-à-dire un an) pour prendre en compte le comportement saisonnier de la production d'énergie renouvelable. Ce modèle peut être étendu à plusieurs scénarios, et il peut aider les décideurs à évaluer quelles régions nécessitent plus d'investissement pour réduire l'impact environnemental de l'opération du cloud.
    
\end{itemize}


Le chapitre~\ref{chap:ccgrid} est organisé comme suit : La Section~\ref{sec:problemStatement_ccgrid} définit le problème abordé, les hypothèses, les modèles et la fonction objective. Les détails sur les contraintes du problème et la façon de le résoudre de manière optimale sont donnés dans la Section~\ref{sec:optimalresolution_ccgrid}. Les expériences sont présentées dans la Section~\ref{sec:experiments_ccgrid}, et leurs résultats sont discutés dans la Section~\ref{sec:analysis-discussion_ccgrid}. Enfin, la Section~\ref{sec:conclusion_ccgrid} conclut le chapitre.


Dans ce qui suit, nous présentons la discussion générale du chapitre~\ref{chap:ccgrid}. Nous avons étudié le problème de réduire l'empreinte carbone de l'exploitation d'une fédération de cloud composée de centres de données cloud répartis géographiquement. La partie informatique de la plateforme cloud existe déjà, serveurs et équipements réseau, et l'idée est d'ajouter des équipements d'infrastructure renouvelable sur site pour introduire de l'énergie à faible intensité de carbone dans l'alimentation électrique des centres de données, car le réseau électrique local peut être à forte intensité de carbone.

Étant donné que le soleil brille partout sur terre, nous avons proposé des panneaux photovoltaïques (PV) pour produire de l'énergie renouvelable et des batteries comme dispositifs de stockage d'énergie pour atténuer l'intermittence intrinsèque de cette énergie pendant la journée et pour les calculs nocturnes. La question est de savoir comment dimensionner la surface de la zone des panneaux photovoltaïques (m²) et la capacité des batteries associées (kWh), compte tenu d'une fédération existante de centres de données distribués autour de la terre, sans négliger le fait que la fabrication de PV et de batteries présente également un impact environnemental.


Nous avons fourni une formulation du problème sous forme de programme linéaire. La particularité de notre formulation est que la modélisation utilise uniquement des variables réelles, compte tenu de notre fonction objective et du contexte du problème. Par conséquent, le programme linéaire permet de résoudre de manière optimale des problèmes de grande taille en temps polynomial, par exemple, en minimisant l'empreinte carbone d'une fédération de neuf sites, chacun avec ses propres conditions météorologiques, sur une période d'un an, heure par heure.


Nous avons démontré que notre programme est capable de calculer le dimensionnement optimal des panneaux solaires et des batteries en seulement quelques minutes. De nombreuses expériences ont donné des résultats que nous avons analysés et discutés, expliquant ce que ces résultats expriment. Par exemple, un résultat intéressant, en fonction des emplacements des centres de données considérés, est que la solution optimale pour réduire l'empreinte carbone est de maintenir un mix énergétique grâce à une configuration hybride comprenant à la fois des panneaux solaires et un réseau classique où la production est faible en carbone, au lieu de proposer une plateforme entièrement renouvelable. De plus, les batteries ne sont pas toujours obligatoires dans chaque emplacement (comme dans le cas du DC de Paris).


Enfin, notre modèle a la flexibilité d'être étendu pour évaluer d'autres scénarios (plus de centres de données, d'autres emplacements, des valeurs d'émissions de carbone différentes ou des charges de travail différentes) et il peut aider les décideurs à élaborer leur stratégie pour réduire l'impact environnemental de l'exploitation du cloud.

\section{Évaluation à long terme du dimensionnement des centres de données cloud}

Dans le chapitre~\ref{chap:ccgrid}, nous avons présenté un modèle initial pour réduire les émissions de carbone de l'exploitation d'une fédération de cloud à court terme (un an) en dimensionnant son infrastructure renouvelable, c'est-à-dire en définissant la surface des panneaux solaires et la capacité des batteries pour chaque centre de données. Étant donné que la fédération de cloud fonctionnera à long terme, le décideur doit être certain des investissements qui seront réalisés pour éviter de gaspiller de l'argent et de générer un impact environnemental avec une mauvaise stratégie. De plus, un processus de planification est soumis à de nombreuses incertitudes qui, si elles ne sont pas prises en compte, diminueront la validité et la crédibilité de la solution.

Le chapitre~\ref{chap:ccgrid-extension} présente une extension du modèle, en se concentrant sur l'exploitation à long terme des centres de données cloud et les incertitudes auxquelles ce processus de dimensionnement est soumis. Dans notre contexte, l'incertitude provient principalement de l'intermittence des sources renouvelables. Par conséquent, le lecteur est introduit à une analyse de la sensibilité de la modélisation aux conditions climatiques. Une autre donnée qui peut influencer le processus de dimensionnement est la valeur des émissions du réseau électrique local. Dans notre modélisation initiale, nous avons utilisé la valeur moyenne de l'année, étant donné que toutes les localisations ne fournissent pas cette valeur avec des intervalles plus courts, variation heure par heure, par exemple. Le lecteur est présenté avec une analyse de l'impact de l'utilisation des informations granulaires des émissions du réseau par rapport à la moyenne annuelle sur le processus de dimensionnement et l'empreinte carbone totale résultante.


Étant donné que l'accent est désormais mis sur l'exploitation à long terme, il est essentiel de considérer l'ensemble du cycle de vie de l'infrastructure renouvelable. Dans le chapitre précédent, nous avons effectué la modélisation en ne tenant compte que de l'impact environnemental de la fabrication des panneaux solaires et des batteries lithium-ion. Cette décision a été prise en raison des données disponibles que nous avons trouvées lors de l'étude du problème. Cependant, l'impact environnemental est également présent dans les autres phases de la durée de vie de ces dispositifs, exploitation, mise au rebut et recyclage. Par conséquent, la modélisation a été mise à jour pour prendre en compte les émissions du cycle de vie de l'infrastructure renouvelable.


Réduire les émissions de carbone en utilisant des panneaux solaires est limité, car ils ne génèrent de l'énergie que lorsque le soleil brille. Par conséquent, ils doivent fournir les opérations du cloud pendant la journée et charger les batteries pour les opérations nocturnes. Dans ce chapitre, nous évaluons si l'utilisation d'éoliennes pourrait encore réduire les émissions de carbone de l'exploitation cloud et le dimensionnement à la fois des panneaux solaires et des batteries, en considérant que le vent peut également être disponible la nuit.


Il est également nécessaire de prendre en compte le fait que, une fois construite, l'infrastructure renouvelable ne peut pas être réduite, cela impliquerait de détruire ou de jeter des panneaux solaires, des batteries et des éoliennes. Par conséquent, une autre stratégie est nécessaire pour faire face au surdimensionnement que l'intermittence des sources renouvelables pourrait causer. Heureusement, une autre partie peut être gérée pour réduire l'impact d'un mauvais dimensionnement : la planification de la charge de travail. Sur la plateforme cloud, une partie importante de la charge de travail est constituée de tâches qui n'ont pas une priorité élevée et dont l'exécution peut être retardée dans le temps, les tâches dites de lot. Chez Meta, 7,5\% de la charge de travail sont des tâches hors ligne~\cite{acun2022holistic} et les tâches de faible priorité consomment en moyenne 20\% des ressources informatiques (CPU et mémoire) des clusters de Google~\cite{googleborg_2020}. Nous présentons une analyse de la viabilité du retard de $\alpha$\% des tâches jusqu'à $\beta$ créneaux horaires (chaque créneau horaire dure 1 heure) pour réduire l'empreinte carbone.


Un autre aspect important à considérer est que la demande de ressources informatiques cloud augmente d'année en année, pour faire face au nombre croissant d'utilisateurs et de demandes d'applications. De 2010 à 2018, Cisco a fourni des prévisions de croissance de la charge de travail pour les cinq années suivantes, mettant à jour les prévisions chaque année. Le dernier rapport, pour la période de 2017 à 2021, prévoyait que le taux de croissance de la charge de travail serait en moyenne de 22\% par an pour les centres de données cloud~\cite{cisco_global_cloud_index_2018}. De plus, de nouvelles générations de serveurs sont lancées avec un matériel informatique plus puissant qui peut être plus économe en énergie. Comme indiqué dans le chapitre~\ref{chap:intro}, l'analyse de~\citet{masanet2020recalibrating} a montré que de 2010 à 2018, la charge de travail des centres de données a augmenté six fois; cependant, l'augmentation de la consommation d'énergie n'a été que de 6\% grâce aux améliorations d'efficacité à la fois du matériel et du logiciel. D'autre part, la fabrication de serveurs émet également du carbone, ce qui ne peut être négligé. En outre, étant donné l'intégration croissante des infrastructures renouvelables dans les centres de données cloud, la plupart des émissions de carbone se déplacent de la consommation d'énergie de l'exploitation du centre de données à la fabrication de l'équipement informatique~\cite{gupta2021_chasingcarbon}.


Jusqu'à présent, nous avons exploré uniquement l'aspect de l'impact environnemental, en termes d'émissions de carbone, de l'exploitation de la fédération de cloud. Une autre dimension d'une importance élevée pour le décideur est le coût monétaire, car l'entreprise ne survivra que si elle génère des bénéfices. Le lecteur se voit également présenter une analyse du coût pour réduire l'empreinte carbone de l'exploitation multi-cloud en utilisant une infrastructure renouvelable sur site. Tout comme l'analyse de l'impact environnemental, nous considérons les coûts de toute la durée de vie des panneaux solaires, des éoliennes et des batteries.

Plus spécifiquement, le chapitre~\ref{chap:ccgrid-extension} présente les contributions suivantes:

\begin{itemize}

\item nous étendons la modélisation pour prendre en compte toutes les émissions du cycle de vie de l'infrastructure renouvelable, de la fabrication à la mise au rebut/recyclage (Section~\ref{sec:lifecicle});
\item nous présentons une évaluation de la réduction possible de l'empreinte carbone si des éoliennes étaient également incluses dans l'infrastructure renouvelable (Section~\ref{sec:add_wt});
\item nous montrons une évaluation concernant la sensibilité du LP aux entrées : i) les incertitudes causées par l'intermittence du rayonnement solaire et de la vitesse du vent, et ce qui doit être pris en compte dans la modélisation pour éviter un sur ou un sous-dimensionnement de l'infrastructure renouvelable ; ii) certaines localités disposent de sources de données avec l'empreinte carbone du réseau à des intervalles de temps d'une heure, et nous montrons une analyse de savoir si cette valeur granulaire affecterait le dimensionnement de l'infrastructure renouvelable (Section~\ref{sec:sensitivity});
\item nous présentons une analyse de la réduction possible de l'empreinte carbone en utilisant la flexibilité de la planification, en retardant les tâches par lots (Section~\ref{sec:flexibility});
\item nous présentons une analyse du moment où il est viable d'ajouter de nouveaux serveurs (qui peuvent remplacer des serveurs de générations plus anciennes) en termes d'empreinte carbone (Section~\ref{sec:costs});
\item nous montrons une analyse de combien il est coûteux (en dollars) de réduire l'empreinte de la fédération de cloud et les gains en termes d'économies monétaires et d'émissions (Section~\ref{sec:new_servers}).
  
\end{itemize}


Le chapitre~\ref{chap:ccgrid-extension} est organisé comme suit. Étant donné que nous étendons le modèle du chapitre~\ref{chap:ccgrid} pour évaluer différents scénarios, chaque scénario a sa propre section, Sections~\ref{sec:lifecicle}, ~\ref{sec:add_wt}, ~\ref{sec:sensitivity}, ~\ref{sec:flexibility}, \ref{sec:costs}, et \ref{sec:new_servers}, et dans chaque section, le lecteur est présenté avec les modifications nécessaires dans la modélisation, les expériences réalisées et les résultats des expériences. Après avoir présenté les scénarios évalués, nous montrons la discussion à la Section\ref{sec:long_term_discussion}. Enfin, la Section\ref{sec:long_term_conclusion} conclut le chapitre.

Dans ce qui suit, nous présentons la discussion générale du chapitre~\ref{chap:ccgrid-extension}. Nous avons étudié le problème de réduire l'impact environnemental à long terme des fédérations de cloud en intégrant une infrastructure renouvelable locale sur les sites où se trouvent les centres de données. Nous avons étendu notre modélisation initiale, présentée dans le chapitre~\ref{chap:ccgrid}, selon les points suivants :

\begin{itemize}
    \item nous avons pris en compte l'ensemble du cycle de vie de l'infrastructure renouvelable ;
    \item nous avons intégré des éoliennes dans le modèle pour réduire davantage l'impact environnemental, en particulier lorsque le soleil ne brille pas ;
    \item nous avons évalué la sensibilité du modèle aux données d'entrée telles que le rayonnement solaire, la vitesse du vent et les valeurs d'émission du réseau ;
    \item nous avons montré que permettre le retardement de la charge de travail peut réduire l'empreinte carbone de l'exploitation cloud et atténuer partiellement l'erreur du processus de dimensionnement causée par l'intermittence des énergies renouvelables, ce qui est important car une fois construite, il n'est pas possible de réduire les dimensions de l'infrastructure renouvelable ;
    \item nous avons mené une analyse des coûts monétaires de la minimisation de l'impact environnemental du cloud, et illustré que l'infrastructure renouvelable peut effectivement réduire les coûts pour les opérateurs cloud ;
    \item nous avons inclus le dimensionnement des équipements informatiques dans le modèle, pour évaluer dans quelle mesure l'adoption de serveurs de nouvelles générations peut réduire l'empreinte carbone, car ils pourraient être plus économes en énergie, mais leur fabrication émet également du carbone.
\end{itemize}

Ces modifications ont été soigneusement apportées pour utiliser des variables et des contraintes linéaires, de sorte que le problème reste résolu de manière optimale en temps polynomial.


\section{Discussion générale }

Le cloud computing est un composant essentiel de notre société numérique moderne, étant donné qu'il prend en charge la majorité des services et des applications que nous utilisons. D'un autre côté, on ne peut négliger l'impact environnemental qu'il présente, qui provient à la fois de la consommation énergétique de son fonctionnement, supérieure à la demande d'électricité de pays entiers, et du cycle de vie de son infrastructure.

Dans cette thèse, nous avons étudié des stratégies visant à réduire l'impact environnemental, en termes d'empreinte carbone, de l'exploitation et du dimensionnement des fédérations de cloud avec des centres de données répartis géographiquement dans le monde entier. Plus précisément, nous avons exploré deux stratégies sensibles au carbone: \guillemotleft follow-the-renewables\guillemotright et le dimensionnement de l'infrastructure renouvelable et des équipements informatiques.

Cette section commence par fournir un aperçu des principales contributions apportées dans cette thèse. Ensuite, nous discutons des opportunités potentielles pour les futures directions de recherche qui s'appuient sur les enseignements tirés du travail présenté dans cette thèse. Enfin, nous présentons les différentes façons dont notre travail a été diffusé, y compris une liste de publications scientifiques qui ont émergé de la recherche menée dans cette thèse.

La première contribution principale de cette thèse est l'analyse de l'impact de la stratégie follow-the-renewables sur à la fois la consommation d'énergie et le réseau, présentée dans le chapitre~\ref{chap:smartgreens}. Cette approche est une solution intéressante pour exploiter la distribution géographique des centres de données cloud à travers le monde afin de réduire la consommation élevée d'électricité à forte intensité carbonée. Cependant, la décision de migrer la charge de travail doit prendre en compte les ressources impliquées dans cette opération, en particulier le réseau.

Nous avons mené des expériences computationnelles pour étudier l'impact des stratégies de follow-the-renewables. Ces expériences ont utilisé des données du monde réel pour la charge de travail, les conditions climatiques, des modèles validés par la communauté scientifique pour la consommation d'énergie et l'utilisation du réseau, ainsi que différentes adaptations du follow-the-renewables.


Les résultats ont démontré que la planification des migrations sans tenir compte du réseau, en particulier, la topologie et l'utilisation du réseau, entraînera une congestion du réseau et un gaspillage d'énergie. Comme vu dans la Section~\ref{sec:wasted_resources_smartgreens}, l'énergie gaspillée pourrait être utilisée pour alimenter les serveurs des centres de données cloud, et elle contribue également à augmenter l'impact environnemental de l'exploitation du cloud. Nous avons proposé un algorithme de planification des migrations qui peut réduire la consommation d'énergie non renouvelable sans impact sur le réseau, par rapport aux travaux de la littérature qui planifient la migration de la charge de travail sans tenir compte du réseau.


La deuxième contribution principale de cette thèse est le modèle permettant de dimensionner à la fois l'infrastructure renouvelable et informatique et de faire fonctionner les fédérations de cloud dans le but de réduire l'empreinte carbone, présenté dans les chapitres~\ref{chap:ccgrid} et ~\ref{chap:ccgrid-extension}.


Le modèle initial proposé dans le chapitre~\ref{chap:ccgrid} était axé sur l'exploitation à court terme sur une durée d'un an et la possibilité de fabriquer sur place des panneaux solaires et des batteries lithium-ion pour générer de l'énergie renouvelable et la stocker afin de faire face à l'intermittence de l'énergie verte.


Le premier aspect clé de la solution proposée est qu'elle résout à la fois les sous-problèmes de dimensionnement et d'exploitation comme un seul problème, ce qui nous permet d'évaluer des décisions telles que l'augmentation des dimensions de l'infrastructure renouvelable sur site d'un centre de données ou la planification de la charge de travail vers différents emplacements géographiques en utilisant l'approche du follow-the-renewables.


Un autre aspect clé du modèle est qu'il prend en compte les caractéristiques spécifiques des emplacements géographiques des centres de données en termes de conditions climatiques, la capacité à générer de l'énergie renouvelable, les besoins en refroidissement et l'approvisionnement en électricité du réseau local, qui peuvent déjà incorporer des sources d'énergie à faible intensité carbonée. Enfin, la solution proposée ne néglige pas que la fabrication de l'infrastructure renouvelable présente également un impact environnemental.


À travers des expériences computationnelles utilisant des données du monde réel pour la charge de travail, les conditions climatiques, les spécifications des serveurs, l'emplacement des centres de données et le mix énergétique du réseau, nous avons démontré que la solution hybride, qui combine l'infrastructure renouvelable sur site et peut utiliser l'électricité du réseau local, est meilleure en termes d'empreinte carbone que le simple fonctionnement des centres de données en utilisant l'électricité du réseau local ou exclusivement l'électricité de l'infrastructure renouvelable sur site.

Nous avons ensuite étendu notre modélisation pour le long terme dans le chapitre~\ref{chap:ccgrid-extension}, ce qui est obligatoire étant donné que les centres de données ont des durées de vie opérationnelles s'étendant sur plus d'une décennie. Nous avons commencé par améliorer la modélisation pour tenir compte de l'empreinte carbone de l'ensemble du cycle de vie de l'infrastructure renouvelable, de la fabrication au rejet ou au recyclage, ce qui fournit des informations plus précises sur l'impact environnemental et réduit le surdimensionnement.


De plus, nous avons également évalué l'inclusion de l'énergie éolienne comme source renouvelable sur site. Nos expériences ont démontré que malgré la réduction supplémentaire de l'empreinte carbone, cela pourrait ne pas être adéquat pour la production renouvelable sur site en raison de ses exigences en termes de surface terrestre, du fait qu'il augmente l'incertitude du processus de dimensionnement et des coûts monétaires plus élevés pour la production d'énergie éolienne. Par conséquent, les meilleurs candidats pour l'infrastructure renouvelable sur site sont les panneaux solaires pour générer de l'énergie et les batteries lithium-ion pour stocker l'énergie afin de la fournir la nuit ou pendant les périodes de faible irradiance.


Nous avons également montré que la planification de la charge de travail peut atténuer une partie de l'impact des erreurs dans le processus de dimensionnement, causées par l'incertitude des conditions climatiques.


En termes de coûts, nous avons montré que l'adoption d'une infrastructure renouvelable sur site est moins chère que le fonctionnement exclusif des centres de données avec de l'électricité provenant uniquement du réseau électrique local. De plus, la solution avec des panneaux solaires et des batteries est la meilleure à la fois en termes environnementaux et monétaires pour les opérateurs de cloud.


Notre modèle nous permet également d'évaluer la réduction potentielle des émissions de carbone en adoptant des serveurs de nouvelles générations qui pourraient être plus économes en énergie, tout en tenant compte de l'empreinte carbone de la fabrication des serveurs. Le modèle est suffisamment flexible pour comparer une génération de serveurs à une autre ou déterminer quelle serait la solution optimale compte tenu de nombreuses générations de serveurs. Dans la solution optimale, les serveurs sont utilisés pendant leur durée de vie prévue. Ce fait peut servir d'inspiration pour prolonger l'utilisation réelle des serveurs, car ils sont puissants en termes de calcul, les mettre au rebut entraîne un impact environnemental et attendre de remplacer les serveurs augmente la probabilité d'avoir une génération de serveurs plus économe en énergie et plus puissante en termes de calcul.


Enfin, le modèle a été soigneusement conçu pour n'utiliser que des variables linéaires. Cela permet au modèle d'être résolu de manière optimale en temps polynomial et d'évaluer les scénarios à long terme en un temps raisonnable. Cette efficacité réduit la consommation d'énergie et l'empreinte carbone associée du processus de dimensionnement lui-même. Les décideurs pourraient adopter ce modèle pour guider leurs efforts visant à réduire l'impact environnemental des plates-formes de cloud computing.


Comme discuté dans la Section~\ref{sec:conclusion_smargreens}, pour évaluer davantage l'impact des stratégies follow-the-renewables, nous devons également prendre en compte l'utilisation du réseau par la charge de travail, ce qui réduit la bande passante disponible pour le processus de migration. De plus, le modèle peut être analysé pour la technologie de virtualisation de conteneurs. Étant donné que les conteneurs sont généralement plus petits que les machines virtuelles, leur temps de migration est plus rapide. Cela peut entraîner la migration de plus de tâches ou permettre la migration vers des centres de données situés plus loin.


Nous avons vu dans le chapitre~\ref{chap:smartgreens} que l'application de la stratégie follow-the-renewables a un potentiel significatif pour réduire les émissions de carbone de l'opération de cloud. Nous ne l'avons pas inclus dans notre modélisation pour le dimensionnement et le fonctionnement des centres de données cloud distribués à l'échelle mondiale, étant donné la latence élevée entre les liens réseau qui connectent ces centres de données, ce qui entraînerait un temps de migration long. Cette analyse doit être réalisée pour évaluer le potentiel de migration de la charge de travail, étant donné que les centres de données situés plus loin pourraient avoir plus de disponibilité en sources à faible intensité de carbone. Une possibilité est d'avoir un seuil pour le temps de migration, ou de migrer uniquement les tâches à faible priorité en tant que tâches en lot.



En ce qui concerne notre approche proposée pour le dimensionnement et le fonctionnement des fédérations de cloud, un point crucial pour le long terme est la dégradation de l'infrastructure renouvelable et informatique et la défaillance de l'équipement informatique. Pour la décision de fabriquer de nouveaux serveurs, le modèle peut être étendu à un niveau de granularité fine au niveau de l'équipement informatique (par exemple, en remplaçant uniquement un disque défaillant). L'analyse des coûts monétaires peut également être appliquée à la décision de fabriquer ou de remplacer de nouveaux serveurs, à condition que les données sur le prix du matériel soient accessibles. De plus, il est possible de formuler un problème d'optimisation multi-objectif entre les coûts en dollars et l'empreinte carbone, tant pour l'infrastructure renouvelable que pour la partie informatique. Une autre possibilité est d'analyser le processus de dimensionnement en tenant compte de l'utilisation d'autres types de matériel pour les calculs, en particulier les processeurs graphiques (GPU) largement utilisés pour les applications d'intelligence artificielle.


Nous avons exploré la décision de dimensionnement pour les fédérations de cloud existantes. Notre solution proposée pourrait également être étendue pour évaluer le placement de nouveaux centres de données dans le but de minimiser l'empreinte carbone. Par exemple, étant donné un ensemble d'options de localisation, leurs caractéristiques respectives en termes de potentiel de génération d'énergie renouvelable, conditions climatiques, besoins en refroidissement, demande de charge de travail, spécifications des serveurs et leur empreinte carbone associée, il serait possible d'effectuer une analyse comparative de l'empreinte carbone de chaque emplacement. Les résultats pourraient être utilisés pour orienter la décision sur l'emplacement du nouveau centre de données.


Enfin, il existe d'autres types d'impact environnemental autres que les émissions de carbone. Par exemple, les plateformes de cloud computing présentent des impacts en termes d'utilisation de l'eau pour le refroidissement, d'extraction des ressources pour la fabrication des circuits intégrés et de l'infrastructure des centres de données, et d'élimination inappropriée de l'équipement informatique, ce qui pourrait entraîner la libération de substances toxiques dans l'environnement. Dans un premier temps, il est nécessaire de modéliser ces types d'impacts environnementaux pour générer des métriques qui nous permettront de les mesurer. Tout comme il existe des métriques pour évaluer la qualité de service, il serait intéressant d'avoir des métriques pour évaluer l'impact environnemental de ces services et applications. Dans un deuxième temps, il sera possible de proposer des solutions pour réduire l'impact environnemental. Par exemple, ces métriques pourraient être incorporées dans des algorithmes d'ordonnancement de charges de travail multi-objectifs ou incluses dans le processus de dimensionnement pour les minimiser.


