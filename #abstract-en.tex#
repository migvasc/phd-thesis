
Cloud computing is one of the backbones of our digital society, providing computational resources for the majority of services and applications we use daily, including e-mail, social networks, internet banking, video streaming, and health applications. Given its importance, we cannot neglect its environmental impact, generated from the energy consumption of the data centers (that could be used to supply entire countries annually) and the life cycle of the infrastructure.

Major cloud providers made commitments and are starting to deploy projects to integrate low-carbon renewable electricity in the operations of their data centers. However, one of the main challenges of renewable energy is its intermittent nature --- its production varies over time, influenced by factors such as time of the day, seasons, and geographic location. There are other essential factors to consider as well. First, the renewable infrastructure also presents environmental impact during its life cycle, and each geographic location has a different capacity for generating renewable power. Additionally, some locations in the world already have the presence of renewable sources in their energy mix.

In this thesis, we study how to reduce the environmental impact --- in terms of carbon footprint --- of operating and sizing cloud data centers. We explore carbon-responsive strategies --- approaches that are aware of their environmental impacts and make informed decisions --- to generate our proposed solutions.

The first mxsain strategy explored is the follow-the-renewables, an approach that allocates and migrates the workload to the data centers with the highest availability of low-carbon-intensive power sources. We evaluated its impact on both the network and energy consumption, and proposed a scheduling algorithm that, by taking into account the network topology and the usage, can plan the migrations without generating network congestion and wastage of energy compared to baselines that do not consider the network.

The second main strategy explored is the sizing of the renewable and IT infrastructure required to minimize the carbon footprint of the cloud data centers: defining the required area of solar panels, number of wind turbines, capacity of batteries (to store excess energy and use when opportune), and number of servers. We propose a Linear Program formulation that considers the specific characteristics of each geographic location of the data centers in terms of capacity for generating renewable power, cooling needs, and the composition of the energy mix, since some locations already have the presence of renewables. Furthermore, we also considered the environmental impact of the renewable infrastructure and manufacturing the servers. Our solution solves the two subproblems of workload scheduling using the follow-the-renewables and sizing the infrastructure as one problem, enabling us to evaluate whether to increase the renewable infrastructure capacity or to allocate the workload to another data center.

Finally, the model employs only linear variables, which enables it to be optimally solved in polynomial time. The model is flexible to evaluate many scenarios. For example, we present an analysis of the feasibility of including wind turbines in the on-site renewable infrastructure, how workload scheduling can mitigate the errors of the sizing process caused by the intermittency, the monetary costs of reducing the carbon footprint, and a possible approach for deciding when to manufacture new servers considering their environmental impact. Decision-makers could use this model to guide their efforts to reduce the carbon emissions of cloud data centers. 


%At first moment, we evaluated a renewable infrastructure composed only of solar panels and batteries, and demonstrated through our experiments that a hybrid configuration that combines both the on-site renewable infrastructure and the power from the local electricity grid is the best option in terms of carbon emissions than operating only using power from the on-site renewable sources or exclusively power from the local grid. At a second moment, we extended the model to show its flexibility to evaluate other scenarios. We show that wind turbines may not be the best option for the on-site renewable infrastructure, given its land area requirements, costs, and capacity to generate power in the locations of the data centers. We also show that it is possible to leverage workload scheduling to mitigate a part of the impact generated by the intermittency in the sizing. In terms of monetary costs, including the on-site renewable infrastructure is cheaper than using only the local electricity grid, and the best option in terms of carbon footprint and monetary costs is the renewable infrastructure composed by solar panels and lithium-ion batteries. In terms of manufacturing new servers, we show that a greedy approach that has information on the current generation server and a forecast of the workload is close to the optimal solution that knows in advance all the configs of the future server generations. Additionally, in the optimal solution, the servers are used longer than the expected lifetime, which can be used as motivation to increase the lifespan of servers, as discarding them presents a significant environmental impact.
